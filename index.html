<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>NeurIPS 2025 Workshop on Multi-Turn Interactions in Large Language Models</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700,700i|Raleway:300,400,500,700,800" rel="stylesheet">

  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <link href="assets/css/style.css" rel="stylesheet">
  
  <style>
    .schedule-table {
      width: 100%;
      border-collapse: collapse;
      background: #fff;
      font-family: Arial, sans-serif;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
      margin: 20px 0;
    }
    .schedule-table th,
    .schedule-table td {
      padding: 12px 15px;
      border-bottom: 1px solid #ccc;
      text-align: left;
    }
    .schedule-table th {
      background-color: #f7f7f7;
      font-weight: bold;
    }
    .schedule-table tbody tr:nth-child(even) {
      background-color: #f9f9f9;
    }
    .schedule-table tbody tr:hover {
      background-color: #f1f1f1;
    }
    /* 响应式设计 */
    @media (max-width: 768px) {
      .schedule-table th,
      .schedule-table td {
        padding: 10px;
      }
    }
    
    /* Unified organizer image styles */
    #organizers .speaker img {
      width: 150px;
      height: 150px;
      object-fit: cover;
      border-radius: 50%;
      margin-bottom: 15px;
    }
    
    /* Unified speaker image styles */
    #speakers .speaker img {
      width: 150px;
      height: 150px;
      object-fit: cover;
      border-radius: 50%;
      margin-bottom: 15px;
    }
    
    /* Unified panelist image styles */
    #panelists .speaker img {
      width: 150px;
      height: 150px;
      object-fit: cover;
      border-radius: 50%;
      margin-bottom: 15px;
    }
    
    /* Unified sponsor image styles */
    #sponsors .speaker img {
      width: 300px;
      height: auto;
      object-fit: contain;
      margin-bottom: 15px;
    }
  </style>
  </head>

<body>

  <header id="header" class="d-flex align-items-center ">
    <div class="container-fluid container-xxl d-flex align-items-center">

      <div id="logo" class="me-auto">
        <a href="index.html" class="scrollto"><img src="assets/img/logo.png" alt="" title=""></a>
      </div>

      <nav id="navbar" class="navbar order-last order-lg-0">
        <ul>
          <li><a class="nav-link scrollto active" href="#hero">Home</a></li>
          <li><a class="nav-link scrollto" href="#about">About</a></li>
          <li><a class="nav-link scrollto" href="#topic">Topics</a></li>
          <li><a class="nav-link scrollto" href="#cfp">Call for Papers</a></li>
          <li><a class="nav-link scrollto" href="#speakers">Speakers</a></li>
          <li><a class="nav-link scrollto" href="#accepted-paper">Accepted Papers</a></li>
          <li><a class="nav-link scrollto" href="#schedule">Schedule</a></li>
          <li><a class="nav-link scrollto" href="#grant">Student Registration Grant</a></li>
          <li><a class="nav-link scrollto" href="#organizers">Organizers</a></li>
          <li><a class="nav-link scrollto" href="#sponsors">Sponsors</a></li>
          <li><a class="nav-link scrollto" href="#faq">FAQ</a></li>
          <li><a class="nav-link scrollto" href="mailto:multiturn-interactions-organizers@googlegroups.com">Contact</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav>

    </div>
  </header><section id="hero">
    <div class="hero-container" data-aos="zoom-in" data-aos-delay="200">
              <h1 class="mb-4 pb-0" style="text-transform: none;">
                
          NeurIPS 2025 Workshop on <br>
          Multi-Turn Interactions in Large Language Models<br>
          </h1>
          <h2 class="mb-4 pb-0" style="text-transform: none; color: white;">
            December 6, 2025<br>
            San Diego Convention Center, San Diego, USA
          </h2>
        
      <div class="social-links" style="margin-top: 25px;">
        <a href="https://x.com/mti_neurips" target="_blank" rel="noopener noreferrer" style="margin-right: 15px; text-decoration: none; color: #1DA1F2;">
          Twitter
        </a>
        <a href="https://openreview.net/group?id=NeurIPS.cc/2025/Workshop/MTI-LLM" target="_blank" rel="noopener noreferrer" style="text-decoration: none; color: #1DA1F2;">
          OpenReview
        </a>
      </div>
    </div>
  </section>
  <main id="main">

    <section id="about">
        <div class="container position-relative" data-aos="fade-up">
            <div class="row">
                <div class="col-lg-12">
                    <h2>About The Workshop</h2>
                    <p style="font-size: 18px;">
                        The field of AI is entering a <b>new era of interaction</b>, profoundly shaped by the capabilities of Large Language Models (LLMs). While multi-turn interaction has been a long-standing pursuit in AI—from dialogue systems to multi-agent coordination—the advent of LLMs has radically transformed this landscape. These models now engage in complex, long-horizon interactions, process diverse data, and make crucial decisions in dynamic, human-centric scenarios.
                    </p>
                    <p style="font-size: 18px;">
                        This leap forward, however, brings forth <b>critical new research questions and challenges</b> that demand immediate attention:
                    </p>
                    <ul style="font-size: 18px;">
                        <li><b>Multi-Turn RL Learning for Agentic Tasks</b> Learning from complex, interactive environments like GUI agents and tool-use scenarios, given the challenges of sparse rewards.</li>
                        <li><b>Maintaining Alignment</b> Understanding human values over extended, multi-turn interactions, preventing "loss of alignment" seen in current models.</li>
                        <li><b>Human-AI Interaction</b> Over time, ensuring models adapt to user goals without compromising safety or fairness.</li>
                        <li><b>Long-horizon Evaluation</b> For LLMs' long-term capabilities, consistency, and strategic abilities in complex, multi-turn tasks.</li>
                    </ul>
                    <p style="font-size: 18px;">
                        The <b>Workshop on Multi-Turn Interactions in LLMs</b> is designed to be the central forum for addressing these pivotal questions. We invite researchers to contribute to defining the next generation of interactive AI, tackling these core challenges, and charting the course for future advancements in AI reasoning and planning. This workshop will concentrate on key areas where the extended use of LLMs presents both new challenges and opportunities, serving as a platform to discuss and refine methods for future improvements and evaluation for practical LLM use cases.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <section id="topic" class="section-with-bg">
      <br>
      <br>
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Topics</h2>
          <p>Our topics include but are not limited to:</p>
        </div>
        <section id="topics">
          <div class="container">
            <div class="row mb-4">
              <div class="col-12">
                <div class="topic-panel interactive-panel p-4 border shadow-sm rounded" style="background: #ffffff;">
                  <b style="font-size: 18px; color: #343a40;">(1) Multi-Turn Settings and Tasks:</b>
                  <p style="color: #6c757d; margin-top: 10px;">
                    Exploring diverse multi-turn interaction paradigms including human-AI, AI-AI, and AI-environment interactions. We welcome research on new multi-turn tasks, position papers on emerging interaction paradigms, and studies on complex scenarios like web agents, tool usage, simulations, and collaborative multi-agent systems. This includes GUI agents, conversational AI, interactive planning, and other long-horizon interactive tasks.
                  </p>
                </div>
              </div>
            </div>

            <div class="row mb-4">
              <div class="col-12">
                <div class="topic-panel interactive-panel p-4 border shadow-sm rounded" style="background: #ffffff;">
                  <b style="font-size: 18px; color: #343a40;">(2) Multi-Turn Frameworks and Algorithms:</b>
                  <p style="color: #6c757d; margin-top: 10px;">
                    Novel methods and frameworks for multi-turn interactions, including various reinforcement learning approaches (PPO, GRPO, etc.), agent architectures, training pipelines, and algorithmic innovations. We seek research on addressing sparse rewards, effective credit assignment, improving training stability, rollout efficiency, and developing new RL methods specifically designed for long-horizon interactive settings with LLMs.
                  </p>
                </div>
              </div>
            </div>

            <div class="row mb-4">
              <div class="col-12">
                <div class="topic-panel interactive-panel p-4 border shadow-sm rounded" style="background: #ffffff;">
                  <b style="font-size: 18px; color: #343a40;">(3) Multi-Turn Evaluation:</b>
                  <p style="color: #6c757d; margin-top: 10px;">
                    Long-horizon evaluation methods that assess consistency, stability, strategic ability, and performance degradation over extended interactions. This includes measuring and predicting performance on complex multi-turn tasks, identifying accumulating errors or unexpected behaviors, and creating comprehensive test environments. We encourage work building upon existing benchmarks like GAIA, TravelPlanner, τ-Bench, and ColBench, as well as developing new evaluation paradigms.
                  </p>
                </div>
              </div>
            </div>

            <div class="row mb-4">
              <div class="col-12">
                <div class="topic-panel interactive-panel p-4 border shadow-sm rounded" style="background: #ffffff;">
                  <b style="font-size: 18px; color: #343a40;">(4) Multi-Turn Challenges:</b>
                  <p style="color: #6c757d; margin-top: 10px;">
                    Addressing critical challenges in extended interactions, with a focus on maintaining alignment and safety over long-term interactions. This includes ensuring LLMs remain aligned with human values, maintaining consistent model personas, accurately tracking and adapting to users' changing goals, ensuring personalization does not compromise safety or fairness, and preventing advanced jailbreaking or hidden goal changes. We welcome research on coherence, personalization, trust, and other emerging challenges in multi-turn settings.
                  </p>
                </div>
              </div>
            </div>
          </div>
        </section>
      </div>
      <br>
      <br>
    </section>
    <section id="cfp">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Call For Papers</h2>
        </div>
        <p>
          The <b>Workshop on Multi-Turn Interactions in LLMs @ NeurIPS 2025</b> invites submissions on the development of novel architectures, algorithms, theoretical analyses, empirical studies, and applications in multi-turn interactions with LLMs. Submissions must present original, unpublished research.
        </p>
        <h3>Key Dates</h3>
        <ul class="fa-ul">
          <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Submission Deadline</b>: <span style="color: red; font-weight: bold;">September 2, 2025, AoE</span></li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Review Period</b>: September 5 - October 6, 2025</li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Notification Date</b>: <del>September 22, 2025</del> <span style="color: red; font-weight: bold;">October 8, 2025, AoE</span></li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Workshop Date</b>: December 6, 2025</li>
        </ul>
        Deadlines are strict and will not be extended under any circumstances. All deadlines follow the <a href="https://time.is/Anywhere_on_Earth">Anywhere on Earth (AoE)</a> timezone.
        <br>
        <br>
        <h3>Submission Site</h3>
        <p>
          Submissions will be managed via OpenReview. Papers will remain private during the review process. All authors must maintain up-to-date OpenReview profiles to ensure proper conflict-of-interest management and paper matching. Incomplete profiles may result in desk rejection.  
          <a href="https://docs.openreview.net/getting-started/creating-an-openreview-profile">Learn how to create an OpenReview profile here</a>.
          <br>
          <br>
          Submit papers through the NeurIPS 2025 Workshop Submission Portal on OpenReview (<a href="https://openreview.net/group?id=NeurIPS.cc/2025/Workshop/MTI-LLM" target="_blank">Multi-Turn Interactions in LLMs Workshop Submission Portal</a>).
        </p>

        <h3>Scope</h3>
        We welcome contributions across a broad spectrum of topics related to our themes. Accepted papers will be presented as posters, with a subset selected for oral presentations. The workshop will take place in person at NeurIPS 2025, with virtual participation options to be confirmed.

        <br>
        <br>
        <h3>Submission Guidelines</h3>
        <h5>Formatting Requirements</h5>

        Submissions must be in English and follow the <a href="assets/files/_NeurIPS_2025__Multi_Turn_Interactions_in_Large_Language_Models.zip">NeurIPS 2025 Workshop LaTeX Template</a>.  
        <br>
        <br>
        Papers must be submitted as a <b>single PDF file</b>:  
        <ul class="fa-ul">
          <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Full Papers</b>: at most 9 pages (main text)</li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span><b>Short Papers</b>: at most 4 pages (main text)</li>
          <li><span class="fa-li"><i class="fa fa-check"></i></span>References and appendices are not included in the page limit, but the main text must be self-contained. Reviewers are not required to read beyond the main text.</li>
        </ul>

        <p>Submissions exceeding the page limit will be desk rejected.</p>

        <h5>Anonymity</h5>
        The workshop follows a <b>double-blind review process</b>. Submissions must be anonymized by removing author names, affiliations, and acknowledgments. Prior work should be cited in the third person. Identifying information, including in supplementary materials, must be omitted.
        <br>
        <br>
        <h5>Dual Submission and Non-Archival Policy</h5>
        <p><b>NeurIPS and ICLR submissions are welcome to submit to our workshop.</b> You can submit your work if it's currently under review at other venues. <del>However, <b>if your paper got accepted by other venues (e.g., NeurIPS) after submission, you have to withdraw from our workshop.</b></del> Papers that are accepted after the submission deadline <b>will not need to withdraw from our workshop</b>, since the workshop is not archival. (That was a mistake previously, sorry!)</p>
        <br>
        <br>
        <h5>Transparency</h5>
        By submitting to the workshop, authors agree that for all accepted papers, the original submission, reviews, and meta-reviews will be made publicly available on OpenReview.
        <br>
        <br>
        <h5>Contact</h5>
        Email at <a href="mailto:multiturn-interactions-organizers@googlegroups.com">multiturn-interactions-organizers@googlegroups.com</a>
      </div>
    </section>

    <section id="speakers" class="section-with-bg">
      <div class="container" data-aos="fade-up">
          <div class="section-header">
              <h2>Speakers and Panelists</h2>
          </div>
          <div class="row">
              <div class="col-md-3 col-sm-4 col-6">
                  <div class="speaker" data-aos="fade-up" data-aos-delay="100" style="text-align: center;">
                      <img src="assets/img/speakers/dawn_song.jpg" alt="Dawn Song" class="img-fluid">
                      <br><a href="https://dawnsong.io/" style="font-size: 1.2em; color: #00356B;">Dawn Song</a></br>
                      <p>UC Berkeley</p>
                  </div>
              </div>
              <div class="col-md-3 col-sm-4 col-6">
                  <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
                      <img src="assets/img/speakers/jason_weston.jpg" alt="Jason Weston" class="img-fluid">
                      <br><a href="https://www.thespermwhale.com/jaseweston/" style="font-size: 1.2em; color: #00356B;">Jason Weston</a></br>
                      <p>Meta FAIR</p>
                  </div>
              </div>
              <div class="col-md-3 col-sm-4 col-6">
                  <div class="speaker" data-aos="fade-up" data-aos-delay="100" style="text-align: center;">
                      <img src="assets/img/speakers/diyi_yang.jpg" alt="Diyi Yang" class="img-fluid">
                      <br><a href="https://cs.stanford.edu/~diyiy/" style="font-size: 1.2em; color: #00356B;">Diyi Yang</a></br>
                      <p>Stanford University</p>
                  </div>
              </div>
              <div class="col-md-3 col-sm-4 col-6">
                  <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
                      <img src="assets/img/speakers/peter_henderson.jpg" alt="Peter Henderson" class="img-fluid">
                      <br><a href="https://www.peterhenderson.co/" style="font-size: 1.2em; color: #00356B;">Peter Henderson</a></br>
                      <p>Princeton University</p>
                  </div>
              </div>
              <div class="col-md-3 col-sm-4 col-6">
                  <div class="speaker" data-aos="fade-up" data-aos-delay="300" style="text-align: center;">
                      <img src="assets/img/speakers/natasha_jaques.jpg" alt="Natasha Jaques" class="img-fluid">
                      <br><a href="https://natashajaques.ai/" style="font-size: 1.2em; color: #00356B;">Natasha Jaques</a></br>
                      <p>UW & Google DeepMind</p>
                  </div>
              </div>
              <div class="col-md-3 col-sm-4 col-6">
                  <div class="speaker" data-aos="fade-up" data-aos-delay="100" style="text-align: center;">
                      <img src="assets/img/speakers/yu_su.jpg" alt="Yu Su" class="img-fluid">
                      <br><a href="https://ysu1989.github.io/" style="font-size: 1.2em; color: #00356B;">Yu Su</a></br>
                      <p>Ohio State University</p>
                  </div>
              </div>
              <div class="col-md-3 col-sm-4 col-6">
                <div class="speaker" data-aos="fade-up" data-aos-delay="100" style="text-align: center;">
                      <img src="assets/img/speakers/will_brown.jpg" alt="Will Brown" class="img-fluid">
                      <br><a href="https://willcb.com/" style="font-size: 1.2em; color: #00356B;">Will Brown</a></br>
                      <p>Prime Intellect</p>
                </div>
            </div>
          </div>
      </div>
  </section>
  
  <section id="panelists" class="section-with-bg">
      <div class="container" data-aos="fade-up">
          <div class="section-header">
              <h2>Confirmed Panelists</h2>
          </div>
          <div class="row">
              <div class="col-md-3 col-sm-4 col-6">
                  <div class="speaker" data-aos="fade-up" data-aos-delay="100" style="text-align: center;">
                      <img src="assets/img/speakers/will_brown.jpg" alt="Will Brown" class="img-fluid">
                      <br><a href="https://willcb.com/" target="_blank" rel="noopener noreferrer" style="font-size: 1.2em; color: #00356B;">Will Brown</a></br>
                      <p>Prime Intellect</p>
                  </div>
              </div>
              <div class="col-md-3 col-sm-4 col-6">
                  <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
                      <img src="assets/img/speakers/eric_wang.jpg" alt="Eric Wang" class="img-fluid">
                      <br><a href="https://eric-xw.github.io/" style="font-size: 1.2em; color: #00356B;">Eric Wang</a></br>
                      <p>UCSB / Simular AI</p>
                  </div>
              </div>
          </div>
      </div>
  </section>
  
    <section id="schedule" style="padding-top: 20px;">
        <div class="container" data-aos="fade-up">
            <div class="section-header">
                <h2>Schedule</h2>
                <p>
                  Tentative workshop schedule. All talks include a Q&amp;A session.
                  For the detailed schedule, please refer to 
                  <a href="https://neurips.cc/virtual/2025/loc/san-diego/workshop/109539" target="_blank" rel="noopener noreferrer">
                    the official NeurIPS workshop page
                  </a>.
                </p>
            </div>
            <style>
                .schedule-table td.time, .schedule-table th:first-child { white-space: nowrap; }
                .schedule-table tr.break-row td { background-color: #fff3cd80 !important; }
                .schedule-table tr.poster-row td { background-color: #d1ecf180 !important; }
            </style>
            <div class="table-responsive">
                <table class="schedule-table table align-middle">
                    <thead>
                        <tr>
                            <th>Time&nbsp;(PDT)</th>
                            <th>Session</th>
                            <th>Speaker</th>
                            <th>Talk&nbsp;Title</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="time">07:50 – 08:00</td>
                            <td>Opening Remarks</td>
                            <td colspan="2">Organizers</td>
                        </tr>
                        <tr>
                            <td class="time">08:00 – 08:30</td>
                            <td>Invited Talk 1</td>
                            <td>Dawn Song (UC Berkeley)</td>
                            <td>Challenges in Multi-Turn Safety Alignment</td>
                        </tr>
                        <tr>
                            <td class="time">08:30 – 09:00</td>
                            <td>Invited Talk 2</td>
                            <td>Natasha Jaques (UW & Google DeepMind)</td>
                            <td>Learning from Human-AI Interaction</td>
                        </tr>
                        <tr>
                            <td class="time">09:00 – 09:30</td>
                            <td>Oral Presentation + Lightning Talk 1</td>
                            <td colspan="2">2 Oral + 5 Spotlight Talks</td>
                        </tr>
                        <tr>
                            <td class="time">09:30 – 10:00</td>
                            <td>Invited Talk 3</td>
                            <td>Diyi Yang (Stanford)</td>
                            <td>Social Simulation</td>
                        </tr>
                        <tr>
                          <td class="time">10:00 – 10:30</td>
                          <td>Invited Talk 4</td>
                          <td>Peter Henderson (Princeton)</td>
                          <td>Multi-Agent Learning</td>
                      </tr>
                        <tr class="poster-row">
                            <td class="time">10:30 – 11:30</td>
                            <td colspan="3">Poster Session 1</td>
                        </tr>
                        <tr class="break-row">
                            <td class="time">11:30 – 13:00</td>
                            <td colspan="3">Lunch Break</td>
                        </tr>
                        <tr>
                            <td class="time">13:00 – 13:30</td>
                            <td>Invited Talk 5</td>
                            <td>Jason Weston (Meta FAIR)</td>
                            <td>Multi-Turn RL for Agentic Tasks</td>
                        </tr>
                        <tr>
                          <td class="time">13:30 – 14:00</td>
                          <td>Invited Talk 6</td>
                          <td>Will Brown (Prime Intellect)</td>
                          <td>Environment Scaling</td>
                      </tr>
                        <tr>
                            <td class="time">14:00 – 14:30</td>
                            <td>Oral Presentation + Lightning Talk 2</td>
                            <td colspan="2">2 Oral + 5 Spotlight Talks</td>
                        </tr>
                        <tr>
                          <td class="time">14:30 – 15:00</td>
                          <td>Invited Talk 7</td>
                          <td>Yu Su (Ohio State University)</td>
                          <td>Planning Capabilities for GUI Agents Task</td>
                        </tr>
                        <tr>
                            <td class="time">15:00 – 15:45</td>
                            <td>Panel Discussion</td>
                            <td colspan="2">Natasha Jaques, Will Brown, Peter Henderson, Diyi Yang, Eric Wang, Yu Su (Coordinator: Weiyan Shi)</td>
                        </tr>
                        <tr class="poster-row">
                          <td class="time">15:45 – 16:45</td>
                          <td colspan="3">Poster Session 2</td>
                        </tr>
                        <tr>
                            <td class="time">16:45 – 17:00</td>
                            <td>Paper Award & Closing Remarks</td>
                            <td colspan="2">Organizers</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
    </section>

    <!-- Accepted Papers -->
    <section id="accepted-paper" class="section-with-bg">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Accepted Papers</h2>
        </div>

        <!-- Oral Papers -->
        <h3 style="margin-top: 30px;">Oral Presentations</h3>
        <ul style="line-height: 2;">
          <li>
            <a href="https://openreview.net/forum?id=LkBUwXOy7b" target="_blank"><strong>Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Junhong Shen, Hao Bai, Lunjun Zhang, Yifei Zhou, Amrith Setlur, Shengbang Tong, Diego Caples, Nan Jiang, Tong Zhang, Ameet Talwalkar, Aviral Kumar</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=Ycred6ETQR" target="_blank"><strong>RefineBench: Evaluating Refinement Capability in Language Models</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Young-jun Lee, Seungone Kim, Byung-kwan Lee, Minkyeong Moon, Yechan Hwang, Jong Myoung Kim, Graham Neubig, Sean Welleck, Ho-jin Choi</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=jJ6F1sDn9i" target="_blank"><strong>MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Zijian Zhou, Ao Qu, Zhaoxuan Wu, Sunghwan Kim, Alok Prakash, Daniela Rus, Jinhua Zhao, Bryan Kian Hsiang Low, Paul Pu Liang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=5gpABTkcUJ" target="_blank"><strong>Quantifying Information Gain and Redundancy in Multi-Turn LLM Conversations</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Abhiram Rao Gorle, Amit Kumar Singh Yadav, Tsachy Weissman</em></p>
          </li>
        </ul>

        <!-- Spotlight Papers -->
        <h3 style="margin-top: 40px;">Spotlight Presentations</h3>
        <details style="margin-top: 15px;">
          <summary style="cursor: pointer; font-weight: 500; padding: 12px; background: #f5f5f5; margin-bottom: 15px; border-radius: 5px;">Click to expand spotlight papers (9 papers)</summary>
          <ul style="margin-top: 10px; line-height: 2;">
          <li>
            <a href="https://openreview.net/forum?id=lm5zScHWBI" target="_blank"><strong>ToolComp: A Multi-Tool Reasoning & Process Supervision Benchmark</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Vaskar Nath, Pranav Vishnu Raja, Jane Yu, Claire Yoon, Sean M. Hendryx</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=hCZsutMyEF" target="_blank"><strong>SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Zhenghai Xue, Longtao Zheng, Qian Liu, Yingru Li, Xiaosen Zheng, Zejun Ma, Bo An</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=wC7IjzOANL" target="_blank"><strong>A Personalized Conversational Benchmark: Towards Simulating Personalized Conversations</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Li Li, Peilin Cai, Ryan A. Rossi, Franck Dernoncourt, Branislav Kveton, Junda Wu, Tong Yu, Linxin Song, Tiankai Yang, Yuehan Qin, Nesreen K. Ahmed, Samyadeep Basu, Subhojyoti Mukherjee, Ruiyi Zhang, Zhengmian Hu, Bo Ni, Yuxiao Zhou, Zichao Wang, Yue Huang, Yu Wang, Xiangliang Zhang, Philip S. Yu, Xiyang Hu, Yue Zhao</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=JSYCLJcniH" target="_blank"><strong>Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Jiaxuan Gao, Wei Fu, Minyang Xie, Shusheng Xu, Chuyi He, Zhiyu Mei, Banghua Zhu, Yi Wu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=3gjuFjV2HR" target="_blank"><strong>What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Wendong Bu, Yang Wu, Qifan Yu, Minghe Gao, Bingchen Miao, Zhenkui Zhang, Kaihang Pan, Yunfei Li, Mengze Li, Wei Ji, Juncheng Li, Siliang Tang, Yueting Zhuang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=DnSxspJCme" target="_blank"><strong>AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Jingxu Xie, Dylan Xu, Xuandong Zhao, Dawn Song</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=JMblCtvaDH" target="_blank"><strong>Task Completion Agents are Not Ideal Collaborators</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shannon Zejiang Shen, Valerie Chen, Ken Gu, Alexis Ross, Zixian Ma, Jillian Ross, Alex Gu, Chenglei Si, Wayne Chi, Andi Peng, Jocelyn J Shen, Ameet Talwalkar, Tongshuang Wu, David Sontag</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=YJAA2PzfDi" target="_blank"><strong>BrowseComp-Plus: A More Fair and Transparent Evaluation  Benchmark of Deep-Research Agent</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Zijian Chen, Xueguang Ma, Shengyao Zhuang, Ping Nie, Kai Zou, Sahel Sharifymoghaddam, Andrew Liu, Joshua Green, Kshama Patel, Ruoxi Meng, Mingyi Su, Yanxi Li, Haoran Hong, Xinyu Shi, Xuye Liu, Nandan Thakur, Crystina Zhang, Luyu Gao, Wenhu Chen, Jimmy Lin</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=ERw9r7wPzl" target="_blank"><strong>WOLF: Werewolf-based Observations for LLM Deception and Falsehoods</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Mrinal Agarwal, Saad Rana, Theo Sundoro, Hermela Berhe, Spencer Kim, Vasu Sharma, Sean O'brien, Kevin Zhu</em></p>
          </li>
          </ul>
        </details>

        <!-- Poster Papers -->
        <h3 style="margin-top: 40px;">Poster Presentations</h3>
        <details style="margin-top: 15px; margin-bottom: 30px;">
          <summary style="cursor: pointer; font-weight: 500; padding: 12px; background: #f5f5f5; margin-bottom: 15px; border-radius: 5px;">Click to expand poster papers (110 papers)</summary>
          <ul style="margin-top: 10px; line-height: 2;">
          <li>
            <a href="https://openreview.net/forum?id=xPWycbxQn9" target="_blank"><strong>ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Haziq Mohammad Khalid, Athikash Jeyaganthan, Timothy Do, Yicheng Fu, Vasu Sharma, Sean O'brien, Kevin Zhu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=W7a4UjLk1I" target="_blank"><strong>DeLLMphi: A Multi-Turn Method for Multi-Agent Forecasting</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Andrew Robert Williams, Martin Weiss, Victoria Feere, Nasim Rahaman, Hugo Larochelle</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=eyzvlUMKJM" target="_blank"><strong>CEDA: Cross-modal Evaluation through Debate Agents for Robust Hallucination Detection</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Susmit Neogi, Wang Yun</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=ma26XnmbU6" target="_blank"><strong>RealWebAssist: A Benchmark for Long-Horizon Web Assistance with Real-World Users</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Suyu Ye, Haojun Shi, Darren Shih, Hyokun Yun, Tanya G. Roosta, Tianmin Shu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=drP7qVUnUt" target="_blank"><strong>Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Reward Design and Credit Assignment</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Quan Wei, Siliang Zeng, Chenliang Li, William Brown, Oana Frunza, Wei Deng, Yuriy Nevmyvaka, Yang Katie Zhao, Alfredo Garcia, Mingyi Hong</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=GQZI346irT" target="_blank"><strong>Saying the Unsaid: Revealing the Hidden Language of Multimodal Systems Through Telephone Games</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Juntu Zhao, Jialing Zhang, Chongxuan Li, Dequan Wang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=h8KFX5HM3N" target="_blank"><strong>Scalability of LLM-Based Multi-Agent Systems for Scientific Code Generation: A Preliminary Study</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Yuru Wang, Kaiyan Zhang, Kai Tian, Sihang Zeng, Xingtai Lv, Ning Ding, Biqing Qi, Bowen Zhou</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=cArAB6Sj5X" target="_blank"><strong>CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Punya Syon Pandey, Yongjin Yang, Jiarui Liu, Zhijing Jin</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=9ZCaACjORW" target="_blank"><strong>Multi-Turn Human–LLM Interaction Through the Lens of a Two-Way Intelligibility Protocol</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Harshvardhan Mestha, Karan Bania, Shreyas V, Sidong Liu, Ashwin Srinivasan</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=h3efVg85TG" target="_blank"><strong>VideoMind: A Chain-of-LoRA Agent for Temporal-Grounded Video Reasoning</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Ye Liu, Kevin Qinghong Lin, Chang Wen Chen, Mike Zheng Shou</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=MVaj7qBFsa" target="_blank"><strong>User-Assistant Bias in LLMs</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Xu Pan, Jingxuan Fan, Zidi Xiong, Ely Hahami, Jorin Overwiening, Ziqian Xie</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=8YcgrMead8" target="_blank"><strong>It's LIT! Reliability-Optimized LLMs with Inspectable Tools</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Ruixin Zhang, Jon Donnelly, Zhicheng Guo, Ghazal Khalighinejad, Haiyang Huang, Alina Jade Barnett, Cynthia Rudin</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=bxhLFVfVmx" target="_blank"><strong>Stability of Preference Alignment for Multi-Turn Control with LLM Policies</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Andrew Silva, Pradyumna Tambwekar, Deepak Edakkattil Gopinath, Jonathan Decastro, Guy Rosman, Avinash Balachandran</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=PPn6XHJa1I" target="_blank"><strong>Let’s Try Again: Eliciting Multi-Turn Reasoning in Language Models via Simplistic Feedback</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Licheng Liu, Zihan Wang, Linjie Li, Chenwei Xu, Yiping Lu, Han Liu, Avirup Sil, Manling Li</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=rZumU1owkr" target="_blank"><strong>FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Xiang Liu, Hong Chen, Xuming Hu, Xiaowen Chu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=vCpv5uKQMc" target="_blank"><strong>Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Boyu Gou, Zanming Huang, Yuting Ning, Yu Gu, Michael Lin, Weijian Qi, Andrei Kopanev, Botao Yu, Bernal Jiménez Gutiérrez, Yiheng Shu, Chan Hee Song, Jiaman Wu, Shijie Chen, Hanane Nour Moussa, Tianshu Zhang, Jian Xie, Yifei Li, Tianci Xue, Zeyi Liao, Kai Zhang, Boyuan Zheng, Zhaowei Cai, Viktor Rozgic, Morteza Ziyadi, Huan Sun, Yu Su</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=hIXaL3a9Ky" target="_blank"><strong>Open-Universe Assistance Games</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Rachel Ma, Jingyi Qu, Andreea Bobu, Dylan Hadfield-menell</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=YKdiS2oE3A" target="_blank"><strong>Tracing Coordination Dynamics in Multi-Turn LLM Discussions</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Angelina Parfenova, Jürgen Pfeffer, Alexander Denzler</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=8KDkAQI5T0" target="_blank"><strong>Persuade Me if You Can: A Framework for Evaluating Persuasion Effectiveness and Susceptibility Among Large Language Models</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Nimet Beyza Bozdag, Shuhaib Mehri, Gokhan Tur, Dilek Hakkani-tür</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=WYfzRJgWbO" target="_blank"><strong>Improved Multi-Agent Collaboration with Multi-Turn Reinforcement Learning</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shuo Liu, Tianle Chen, Christopher Amato</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=T16WNvb9lj" target="_blank"><strong>REFRAG: Rethinking RAG based Decoding</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Xiaoqiang Lin, Aritra Ghosh, Bryan Kian Hsiang Low, Anshumali Shrivastava, Vijai Mohan</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=DNLfJbGV6D" target="_blank"><strong>How Can Input Reformulation Improve Tool Usage Accuracy in a Complex Dynamic Environment? A Study on τ -bench</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Venkatesh Mishra, Amir Saeidi, Satyam Raj, Mutsumi Nakamura, Jayanth Srinivasa, Gaowen Liu, Ali Payani, Chitta Baral</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=AObOnFR1Tv" target="_blank"><strong>Probe by Gaming: A Game-based Benchmark for Assessing Conceptual Knowledge in LLMs</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shuhang Xu, Weijian Deng, Yixuan Zhou, Fangwei Zhong</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=nPgh13kzhW" target="_blank"><strong>Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM Prompting</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shashidhar Reddy Javaji, Bhavul Gauri, Zining Zhu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=CD42kp2k2O" target="_blank"><strong>Efficient Reinforcement Learning for Optimizing Multi-turn Student Outcomes with LLM Tutors</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Hyunji Nam, Omer Gottesman, Amy Zhang, Dean Foster, Emma Brunskill, Lyle Ungar</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=cWBxoX7v6z" target="_blank"><strong>Collaborative Prediction: Tractable Information Aggregation via Agreement</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Natalie Collina, Ira Globus-harris, Surbhi Goel, Varun Gupta, Aaron Roth, Mirah Shi</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=Qvb3aLBB2k" target="_blank"><strong>SMAGDi: Socratic Multi Agent Interaction Graph Distillation for Efficient High Accuracy Reasoning</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Aayush Aluru, Myra N. Malik, Samarth Patankar, Spencer Kim, Kevin Zhu, Vasu Sharma, Sean O'brien</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=mEwpZUsynY" target="_blank"><strong>State-Induced Risk Amplification of AI Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Rebecka Nordenlöw, Takayuki Osogami, Lauren Quigley, Sara E. Berger, Rachel K. E. Bellamy</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=pDOtqzaZAf" target="_blank"><strong>MAC: A Multi-Agent Framework for Interactive User Clarification in Multi-turn Conversations</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Emre Can Acikgoz, Jinoh Oh, Joo Hyuk Jeon, Jie Hao, Heng Ji, Dilek Hakkani-tür, Gokhan Tur, Xiang Li, Chengyuan Ma, Xing Fan</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=TyMA8fpmsW" target="_blank"><strong>Exploring exploration with foundation agents in interactive environments</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Daniel P. Sawyer, Nan Rosemary Ke, Hubert Soyer, Martin Engelcke, John Reid, David P Reichert, Drew Arad Hudson, Alexander Lerchner, Danilo Jimenez Rezende, Timothy P Lillicrap, Michael Curtis Mozer, Jane X Wang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=l7NYIYODoQ" target="_blank"><strong>PyVision: Agentic Vision with Dynamic Tooling</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shitian Zhao, Haoquan Zhang, Shaoheng Lin, Ming Li, Qilong Wu, Kaipeng Zhang, Chen Wei</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=ZxRznpOQFT" target="_blank"><strong>Characterization and Detection of Incompleteness and Ambiguity in Multi-Turn Interactions with LLMs</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Riya Naik, Ashwin Srinivasan, Swati Agarwal, Estrid He</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=7vn3zLUJsg" target="_blank"><strong>Alignment via Competition: Emergent Alignment from Differently Misaligned Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Natalie Collina, Surbhi Goel, Aaron Roth, Emily Ryu, Mirah Shi</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=zjUMT9uu68" target="_blank"><strong>Interleaved Reasoning for Large Language Models via Reinforcement Learning</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Roy Xie, David Qiu, Deepak Gopinath, Dong Lin, Yanchao Sun, Chong Wang, Saloni Potdar, Bhuwan Dhingra</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=iS49teIy7h" target="_blank"><strong>The Influence of Scaffolds on Coordination Scaling Laws in LLM Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Mariana Meireles, Rupali Bhati, Niklas Lauffer, Cameron Allen</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=zHMwFgJsmk" target="_blank"><strong>CaRT: Teaching LLM Agents to Know When They Know Enough</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Grace Liu, Yuxiao Qu, Jeff Schneider, Aarti Singh, Aviral Kumar</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=0oxelK4W6c" target="_blank"><strong>RAFFLES: Reasoning-based Attribution of Faults for LLM Systems</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Chenyang Zhu, Spencer Hong, Jingyu Wu, Kushal Chawla, Yuhui Tang, Youbing Yin, Nathan Wolfe, Erin Babinsky, Daben Liu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=uSijBMsVqW" target="_blank"><strong>MAREval: A Multi-Agent Framework for Evaluating Natural Language Recommendation Explanations</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Reza Yousefi Maragheh, Jayesh Uddhav Kudase, Aysenur Inan, Ramin Giahi, Kai Zhao, Jianpeng Xu, Jason Cho, Evren Korpeoglu, Sushant Kumar</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=bqwh9DQVlA" target="_blank"><strong>ObjexMT: Objective Extraction and Metacognitive Calibration for LLM‑as‑a‑Judge under Multi‑Turn Jailbreaks</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Hyunjun Kim, Junwoo Ha, Haon Park, Sangyoon Yu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=kAkWp5v0c5" target="_blank"><strong>Estimating the Empowerment of Language Model Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Jinyeop Song, Jeff Gore, Max Kleiman-weiner</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=3QOfj38jwf" target="_blank"><strong>ExploraTutor: A Dataset for Children’s Exploratory Dialogue by Integrating Multiple Educational theories</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Siqi Xie, Yaxin Xu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=EhRz3a6AEd" target="_blank"><strong>ChatCLIDS: Simulating Persuasive AI Dialogues to Promote Closed-Loop Insulin Adoption in Type 1 Diabetes Care</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Zonghai Yao, Talha Chafekar, Junda Wang, Shuo Han, Feiyun Ouyang, Junhui Qian, Lingxi Li, Hong Yu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=1YjrWLAXJr" target="_blank"><strong>$\textit{The Traitors}$: Deception and Trust in Multi-Agent Language Model Simulations</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Pedro M. P. Curvo</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=Ui0mNJzfSC" target="_blank"><strong>LLM Rationalis? Measuring bargaining capabilities of AI negotiators</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Cheril Shah, Akshit Agarwal, Kanak Garg, Mourad Heddaya</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=LTarXk40PR" target="_blank"><strong>Reinforced Reasoning for Interactive Multi-step Embodied Planning</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Di Wu, Jiaxin Fan, Junzhe Zang, Guanbo Wang, Wei Yin, Wenhao Li, Bo Jin</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=xuivQOPLeP" target="_blank"><strong>Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Alexander Duffy, Samuel J Paech, Ishana Shastri, Elizabeth Karpinski, Baptiste Alloui-cros, Matthew Lyle Olson, Tyler Marques</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=7AetgL7eVL" target="_blank"><strong>Multi-Agent-as-Judge: Aligning LLM-Agent-Based Automated Evaluation with Multi-Dimensional Human Evaluation</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Jiaju Chen, Yuxuan Lu, Xiaojie Wang, Huimin Zeng, Jing Huang, Jiri Gesi, Ying Xu, Dakuo Wang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=VNPGUGbC1p" target="_blank"><strong>SkyRL-SQL: Multi-turn SQL Data Agents via RL</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shu Liu, Alan Zhu, Sumanth Hegde, Shiyi Cao, Shuo Yuan, Samion Suwito, Tyler Griggs, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=pERJAy5kI1" target="_blank"><strong>Traxgen: Ground-Truth Trajectory Generation for AI Agent Evaluation</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Maria Emilia Mazzolenis, Ruirui Zhang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=XZpIu68yW6" target="_blank"><strong>The Automated but Risky Game: Modeling Agent-to-Agent Negotiations and Transactions in Consumer Markets</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shenzhe Zhu, Jiao Sun, Yi Nian, Tobin South, Alex Pentland, Jiaxin Pei</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=BzBqRAbdFC" target="_blank"><strong>Leveraging In-Context Learning for Language Model Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shivanshu Gupta, Sameer Singh, Ashish Sabharwal, Tushar Khot, Ben Bogin</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=oQdo7H38dC" target="_blank"><strong>A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Hong Je-gal, Chanbin Yi, Hyun-suk Lee</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=CwiMAhmDG1" target="_blank"><strong>Learning to be Proactive from Missed User-Signals in Multi-turn Dialogues</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Saba Rahimi, Sivapriya Vellaichamy, Kelly Patel, Thomas Cook, Zhen Zeng, Sumitra Ganesh</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=It7AgR3A9H" target="_blank"><strong>Multi-Turn LLM Systems for Diagnostic Decision-Making: Considerations, Biases, and Challenges</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Benjamin Liu, Sejong Kim, Drona Thoka, Varun Puttagunta, Kaylin Sheng, Mark Li, Kiran Nijjer, Adnan Ahmed, Thi Uyen Hanh Le, Sai Chidvilas Gudiboina, Ali Ugur, Kevin Zhu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=rhgO9ucwQR" target="_blank"><strong>$\mathbf{T^3}$: Reducing Belief Deviation in Reinforcement Learning for Active Reasoning</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Deyu Zou, Yongqiang Chen, Jianxiang Wang, Garry Yang, Mufei Li, Qing Da, Pan Li, Yu Gong, James Cheng</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=uZE8mTYvHE" target="_blank"><strong>OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Yifu Lu, Shengjie Liu, Li Dong</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=m0DL9EHAT6" target="_blank"><strong>Firm or Fickle? Evaluating Large Language Models Consistency in Sequential Interactions</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Yubo Li, Yidi Miao, Xueying Ding, Ramayya Krishnan, Rema Padman</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=8nitMHM0YX" target="_blank"><strong>Towards Trajectory-Level Alignment: Detecting Intent Drift in Long-Horizon LLM Dialogues</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Jianming Lai</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=R0mmX6BEau" target="_blank"><strong>StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production–Living Simulations with Stardew Valley</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Weihao Tan, Changjiu Jiang, Yu Duan, Mingcong Lei, Li Jiageng, Yitian Hong, Xinrun Wang, Bo An</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=ZCi58UP9uR" target="_blank"><strong>AgentChangeBench: A Multi-Dimensional Evaluation Framework for Goal-Shift Robustness in Conversational AI</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Manik Rana, Calissa Man, Anotida Expected Msiiwa, Jeffrey Paine, Ahan M R</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=yPWJG9wgll" target="_blank"><strong>A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Ruiyi Wang, Prithviraj Ammanabrolu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=F6fs7Uitc4" target="_blank"><strong>One-Pass to Reason: Token Duplication and Block-Sparse Mask for Efficient Fine-Tuning on Multi-Turn Reasoning</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Ritesh Goru, Shanay Mehta, Prateek Jain</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=GmodkWwMV3" target="_blank"><strong>Verlog: Context-lite Multi-turn Reinforcement Learning framework for Long-Horizon LLM Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Wentse Chen, Jiayu Chen, Hao Zhu, Jeff Schneider</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=BV6QBwZkfK" target="_blank"><strong>Disclosure Audits for LLM Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Saswat Das, Jameson Sandler, Ferdinando Fioretto</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=QPIF5FVc4f" target="_blank"><strong>Do Large Language Models Defend Their Beliefs Consistently?</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Arka Pal, Arthur Liang, Teo Kitanovski, Akilesh Potti, Micah Goldblum</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=6ZvINpYdOA" target="_blank"><strong>SENTINEL: Sentiment Evolution and Narrative Tracking in Extended LLM Interactions</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Pranav Anuraag, Ethan Xu, Alexander Arutchev, Asher Nerenberg</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=Y0sJzEaNaO" target="_blank"><strong>Graph of Attacks: Improved Black-Box and Interpretable Jailbreaks for LLMs</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Mohammad Akbar-tajari, Mohammad Taher Pilehvar, Mohammad Mahmoody</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=uALCxj1tNe" target="_blank"><strong>Optimizing for Persuasion Improves LLM Generalization: Evidence from Quality-Diversity Evolution of Debate Strategies</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Aksel Joonas Reedi, Corentin Léger, Julien Pourcel, Loris Gaven, Perrine Charriau, Guillaume Pourcel</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=BE00LfP4Dv" target="_blank"><strong>Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Melik Ozolcer, Sang Won Bae</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=YDGj4W3ZSS" target="_blank"><strong>Goal Alignment in LLM-Based User Simulators for Conversational AI</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shuhaib Mehri</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=dLeIT1YigB" target="_blank"><strong>Show or Tell? Interactive Task Learning with Large Language Models</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Jacob Sansom, Muhammad Khalifa, Honglak Lee, Joyce Chai</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=8nDty2iFl1" target="_blank"><strong>AURA: A Diagnostic Framework for Tracking User Satisfaction of Interactive  Planning Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Takyoung Kim, Janvijay Singh, Shuhaib Mehri, Emre Can Acikgoz, Sagnik Mukherjee, Nimet Beyza Bozdag, Sumuk Shashidhar, Gokhan Tur, Dilek Hakkani-tür</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=ePGtpjbr5g" target="_blank"><strong>Automating Deception: Scalable Multi-Turn LLM Jailbreaks</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Adarsh Kumarappan, Ananya Mujoo</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=ka0GEintPX" target="_blank"><strong>OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Ziyi Wang, Yuxuan Lu, Wenbo Li, Amirali Amini, Bo Sun, Yakov Bart, Weimin Lyu, Jiri Gesi, Tian Wang, Jing Huang, Yu Su, Upol Ehsan, Malihe Alikhani, Toby Jia-jun Li, Lydia Chilton, Dakuo Wang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=r0i7GPoYnE" target="_blank"><strong>The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Akshit Sinha, Arvindh Arun, Shashwat Goel, Steffen Staab, Jonas Geiping</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=fN4PJNYgs3" target="_blank"><strong>Stop-RAG: Value-Based Retrieval Control for Iterative RAG</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Jaewan Park, Solbee Cho, Jay-yoon Lee</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=21sPEvGUL2" target="_blank"><strong>Orchestrator: Active Inference for Multi-Agent Systems in Long-Horizon Tasks</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Lukas Beckenbauer, Johannes-lucas Löwe, Ge Zheng, Alexandra Brintrup</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=foZgsZURxU" target="_blank"><strong>Reinforcement Learning for Long-Horizon Multi-Turn Search Agents</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Vivek Kalyan, Martin Andrews</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=gBwovFgeK8" target="_blank"><strong>Sotopia-RL: Reward Design for Social Intelligence</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Haofei Yu, Zhengyang Qi, Yining Zhao, Kolby Nottingham, Keyang Xuan, Bodhisattwa Prasad Majumder, Hao Zhu, Paul Pu Liang, Jiaxuan You</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=1zNmEA6UqC" target="_blank"><strong>Customer-R1: personalized simulation of Human Behaviors via RL-based LLM Agent in Online Shopping</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Ziyi Wang, Yuxuan Lu, Yimeng Zhang, Jing Huang, Dakuo Wang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=fgCOkyJG3f" target="_blank"><strong>PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Weizhi Zhang, Xinyang Zhang, Chenwei Zhang, Liangwei Yang, Jingbo Shang, Zhepei Wei, Henry Peng Zou, Zijie Huang, Zhengyang Wang, Yifan Gao, Xiaoman Pan, Lian Xiong, Jingguo Liu, Philip S. Yu, Xian Li</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=NUSYIHi4eg" target="_blank"><strong>Language Models Rate Their Own Actions As Safer</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Dipika Khullar, Jack Hopkins, Rowan Wang, Fabien Roger</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=TpIywUYWWw" target="_blank"><strong>PrefDisco: Evaluating Proactive Personalization through Interactive Preference Discovery</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shuyue Stella Li, Avinandan Bose, Faeze Brahman, Simon Shaolei Du, Pang Wei Koh, Maryam Fazel, Yulia Tsvetkov</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=3eJU2zwMz4" target="_blank"><strong>Conformity, Inertia, and Value Alignment in Multi-Turn LLM Deliberation</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Pratik S. Sachdeva, Tom Van Nuenen</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=IPpOtWGmdf" target="_blank"><strong>WebGraphEval: Multi-Turn Trajectory Evaluation for Web Agents using Graph Representation</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Yaoyao Qian, Yuanli Wang, Jinda Zhang, Yun Zong, Meixu Chen, Hanhan Zhou, Jindan Huang, Yifan Zeng, Xinyu Hu, Chan Hee Song, Danqing Zhang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=yd3c3Xztgj" target="_blank"><strong>BrowserArena: Evaluating LLM Agents on Real-World Web Navigation Tasks</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Sagnik Anupam, Davis Brown, Shuo Li, Eric Wong, Hamed Hassani, Osbert Bastani</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=GIvfdmlvMA" target="_blank"><strong>Benchmarking Correctness and Security in Multi-Turn Code Generation</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Ruchit Rawal, Jeffrey Yang Fan Chiang, Jeffery Siyuan Tian, Aastha Mahajan, Tom Goldstein, Yizheng Chen</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=9sH0s3g3Mi" target="_blank"><strong>The Chameleon Nature of LLMs: Quantifying Multi-Turn Stance Instability in Search-Enabled Language Models</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shivam Ratnakar, Sanjay Raghavendra</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=MIhA9OQFxM" target="_blank"><strong>Are LLMs Generalist Hanabi Agents?</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Mahesh Ramesh, Aswinkumar Ramkumar, Pavan Thodima, Kaousheik Jayakumar, Aniket Rege</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=YHcHQY8TIY" target="_blank"><strong>WEBSERV: A Browser-Server Environment for Efficient Training of Reinforcement Learning-based Web Agents at Scale</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Yuxuan Lu, Jing Huang, Hui Liu, Jiri Gesi, Yan Han, Shihan Fu, Tianqi Zheng, Dakuo Wang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=SXcJh8hoLz" target="_blank"><strong>AsymPuzl: An Asymmetric Puzzle for multi-agent cooperation</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Xavier Cadet, Edward Koh, Peter Chin</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=HBx2K7SVYh" target="_blank"><strong>How to Train Your LLM Web Agent: A Statistical Diagnosis</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Dheeraj Vattikonda, Santhoshi Ravichandran, Emiliano Penaloza, Hadi Nekoei, Megh Thakkar, Thibault Le Sellier De Chezelles, Nicolas Gontier, Miguel Muñoz-mármol, Sahar Omidi Shayegan, Stefania Raimondo, Xue Liu, Alexandre Drouin, Laurent Charlin, Alexandre Piché, Alexandre Lacoste, Massimo Caccia</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=FwItUoaLqe" target="_blank"><strong>Modeling and Predicting Multi-Turn Answer Instability in Large Language Models</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Jiahang He, Rishi Ramachandran, Neel Ramachandran, Aryan Katakam, Kevin Zhu, Sunishchal Dev, Ashwinee Panda, Aryan Shrivastava</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=uqMPNWvMkp" target="_blank"><strong>CRMWeaver: Building Powerful Business Agent via Agentic RL and Shared Memories</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Yilong Lai, Yipin Yang, Jialong Wu, Zhenglin Wang, Ting Liang, Linjianguo, Keping Yang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=aKChEjaJpZ" target="_blank"><strong>Toward Community-Driven Agents for Machine Learning Engineering</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Sijie Li, Weiwei Sun, Shanda Li, Ameet Talwalkar, Yiming Yang</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=Oly616p1yG" target="_blank"><strong>Semantic Context for Tool Orchestration</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Robert Müller</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=6eN5FZJuLI" target="_blank"><strong>Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Chenxing Wei, Hong Wang, Ying Tiffany He, Fei Yu, Yao Shu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=IYjNoKV0zL" target="_blank"><strong>TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Sarik Ghazarian, Abhinav Gullapalli, Swair Shah, Anurag Beniwal, Nanyun Peng, Narayanan Sadagopan, Zhou Yu</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=WriYV2ipL8" target="_blank"><strong>Large Language Models Develop Novel Social Biases Through Adaptive Exploration</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Addison J. Wu, Ryan Liu, Xuechunzi Bai, Thomas L. Griffiths</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=ZaxCviYEvT" target="_blank"><strong>MELISSA: Multi-level Evaluation with LLM-based Integrated Self-Scrutiny and Auditing</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Amirhossein Afsharrad, Sri Jaladi, Nima Yazdani, Ali Ansari, Seyed Shahabeddin Mousavi, Sanjay Lall</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=ro1sa4iuDJ" target="_blank"><strong>Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Prasoon Varshney, Makesh Narsimhan Sreedhar, Liwei Jiang, Traian Rebedea, Christopher Parisien</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=Gc4CcLKZP5" target="_blank"><strong>ParetoMIL: Early Risk Detection in Dialogue under Weak Supervision</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Avinash Baidya, Xinran Liang, Ruocheng Guo, Kamalika Das, Xiang Gao</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=u7XOqbCZ55" target="_blank"><strong>MultiScale Contextual Bandits for Long Term Objectives</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Richa Rastogi, Yuta Saito, Thorsten Joachims</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=1Ynbsc8e7F" target="_blank"><strong>ConDABench: Interactive Evaluation of Language Models for Data Analysis</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Avik Dutta, Priyanshu Gupta, Hosein Hasanbeig, Rahul Pratap Singh, Harshit Nigam, Sumit Gulwani, Arjun Radhakrishna, Gustavo Soares, Ashish Tiwari</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=JDdJghGm6K" target="_blank"><strong>AI Debaters are More Persuasive when Arguing in Alignment with Their Own Beliefs</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>María Victoria Carro, Denise Alejandra Mester, Facundo Nieto, Oscar Agustín Stanchi, Guido Ernesto Bergman, Mario Leiva, Luca Nicolás Forziati Gangi, Eitan Sprejer, Francisca Gauna Selasco, Juan Gustavo Corvalan, Maria Vanina Martinez, Gerardo Simari</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=eceX2knsGZ" target="_blank"><strong>Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Moises Andrade, Joonhyuk Cha, Brandon Ho, Vriksha Srihari, Karmesh Yadav, Zsolt Kira</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=CdZaamCf5Y" target="_blank"><strong>Studying Coordination and Collusion in Multi-Agent LLM Code Reviews</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Jennifer Za, Aristeidis Panos, Roger Dearnaley, Samuel Albanie</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=lGYJdWYUOf" target="_blank"><strong>Delay-of-Gratification as a Multi-Agent Survival Micro-benchmark for Long-Horizon LLMs: Social Exposure, Personas, and Tool Use Budgets</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Olga Manakina, Igor Bogdanov, Chung-horng Lung</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=QwfXAWe06Q" target="_blank"><strong>Improving Language Agents through BREW: Bootstrapping expeRientially-learned Environmental knoWledge</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shashank Kirtania, Param Biyani, Priyanshu Gupta, Yasharth Bajpai, Roshni Iyer, Sumit Gulwani, Gustavo Soares</em></p>
          </li>
          <li>
            <a href="https://openreview.net/forum?id=HdNwfRubZW" target="_blank"><strong>Fathom-Search-4B: Scaling DeepSearch Reasoning Capabilities via RL</strong></a>
            <p style="margin: 5px 0 15px 0; color: #666; font-size: 0.95em;"><em>Shreyas Singh, Kunal Singh, Pradeep Moturi</em></p>
          </li>
          </ul>
        </details>
          </div>
    </section>

    <section id="grant">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Student Registration Grant</h2>
        </div>
        <p>
          The <strong>Multi-Turn Interactions in LLMs (MTI-LLM)</strong> Workshop at <strong>NeurIPS 2025</strong> is pleased to announce limited <strong>financial support</strong> for student authors of accepted workshop papers.
        </p>
        <p>
          Thanks to our generous sponsors — <strong>Meta AI</strong> and <strong>Orby AI (now Uniphore)</strong> — we are offering registration reimbursement grants to ensure broader student participation in the NeurIPS community.
        </p>

        <h3>💡 Eligibility & Coverage</h3>
        <ul>
          <li>Only the student registration fee for <strong>workshop</strong> (<strong>$175 early</strong> and <strong>$230 late</strong>) is eligible for reimbursement, we are having 10-15 places.</li>
          <li>Support will be issued <strong>via reimbursement</strong> after the conference (not as direct payment).</li>
          <li><strong>Travel, accommodation, or other expenses are not covered</strong> under this program.</li>
        </ul>

        <h3>💬 Reimbursement Policy</h3>
        <p>
          Reimbursements will be processed <strong>after NeurIPS 2025</strong> upon submission of a <strong>valid payment receipt</strong> for the student registration.
        </p>
        <p>
          This ensures funds are distributed fairly to participants who <strong>attend and present</strong> at the workshop.
        </p>

        <h3>🗓️ Key Dates</h3>
        <ul>
          <li><strong>Application Deadline</strong>: October 20, 2025</li>
          <li><strong>Notification of Results</strong>: October 27, 2025</li>
        </ul>

        <h3>🎯 Priority Considerations</h3>
        <p>Preference will be given to:</p>
        <ul>
          <li>students presenting accepted papers at MTI-LLM @ NeurIPS 2025</li>
          <li>students without other funding support (e.g., from advisor or institution)</li>
          <li>students from underrepresented regions or institutions</li>
        </ul>

        <h3>Registration Grant Recipients</h3>
        <ul>
          <li>Huiqi Zou - Northeastern University - PhD</li>
          <li>Arthur Liang - MIT - Undergraduate</li>
          <li>Adarsh Kumarappan - California Institute of Technology - Undergraduate</li>
          <li>Moises Andrade - Georgia Institute of Technology - Incoming PhD Student</li>
          <li>Mrinal Agarwal - Algoverse - Junior at Emerald High School</li>
          <li>Yaoyao Qian - Northeastern University - Master's</li>
          <li>Junhong Shen - Carnegie Mellon University - PhD</li>
          <li>Xueguang Ma - University of Waterloo - PhD</li>
          <li>Li Li - University of Southern California - PhD</li>
          <li>Ao Qu - Massachusetts Institute of Technology - PhD</li>
          <li>Jingxu Xie - UC Berkeley - PhD</li>
          <li>Young-Jun Lee - KAIST - PhD</li>
          <li>Hao Bai - UIUC - PhD</li>
          <li>Zhiyuan Hu - MIT - PhD</li>
        </ul>
      </div>
    </section>

    <section id="organizers">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Organizers</h2>
          <p>This workshop is organized by</p>
        </div>

        <div class="row">
          <div class="col-lg col-md-4 col-sm-6 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/simon_yu.jpeg" alt="Simon Yu" class="img-fluid">
              <br><a href="https://simonucl.github.io/" style="font-size: 1.2em; color: #00356B;">Simon Yu</a></br>
              <p>Northeastern University</p>
            </div>
          </div>
          <div class="col-lg col-md-4 col-sm-6 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/bo_liu.jpg" alt="Bo Liu" class="img-fluid">
              <br><a href="https://benjamin-eecs.github.io/" style="font-size: 1.2em; color: #00356B;">Bo Liu</a></br>
              <p>National University of Singapore / Meta</p>
            </div>
          </div>
           <div class="col-lg col-md-4 col-sm-6 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/yifei_zhou.png" alt="Yifei Zhou" class="img-fluid">
              <br><a href="https://yifeizhou02.github.io/" style="font-size: 1.2em; color: #00356B;">Yifei Zhou</a></br>
              <p>UC Berkeley / xAI</p>
            </div>
          </div>
          <div class="col-lg col-md-4 col-sm-6 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/mickel_liu.png" alt="Mickel Liu" class="img-fluid">
              <br><a href="https://mickel-liu.github.io/" style="font-size: 1.2em; color: #00356B;">Mickel Liu</a></br>
              <p>University of Washington</p>
            </div>
          </div>
           <div class="col-lg col-md-4 col-sm-6 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/kai_zhang.jpg" alt="Kai Zhang" class="img-fluid">
              <br><a href="https://drogozhang.github.io/" style="font-size: 1.2em; color: #00356B;">Kai Zhang</a></br>
              <p>Ohio State University</p>
            </div>
          </div>
        </div>
        <div class="row justify-content-center">
           <div class="col-lg col-md-4 col-sm-6 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/hanxu_hu.png" alt="Hanxu Hu" class="img-fluid">
              <br><a href="https://hanxuhu.github.io/" style="font-size: 1.2em; color: #00356B;">Hanxu Hu</a></br>
              <p>University of Zurich / Microsoft Research Asia</p>
            </div>
          </div>
           <div class="col-lg col-md-4 col-sm-6 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/leon_guertler.jpg" alt="Leon Guertler" class="img-fluid">
              <br><a href="https://scholar.google.com/citations?user=FMO0YSYAAAAJ&hl=en" style="font-size: 1.2em; color: #00356B;">Leon Guertler</a></br>
              <p>Singapore A*STAR</p>
            </div>
          </div>
           <div class="col-lg col-md-4 col-sm-6 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/leshem_choshen.avif" alt="Leshem Choshen" class="img-fluid">
              <br><a href="https://ktilana.wixsite.com/leshem-choshen" style="font-size: 1.2em; color: #00356B;">Leshem Choshen</a></br>
              <p>MIT / MIT-IBM Watson AI Lab</p>
            </div>
          </div>
           <div class="col-lg col-md-4 col-sm-6 col-6">
            <div class="speaker" data-aos="fade-up" data-aos-delay="200" style="text-align: center;">
              <img src="assets/img/organizers/weiyan_shi.jpg" alt="Weiyan Shi" class="img-fluid">
              <br><a href="https://wyshi.github.io/" style="font-size: 1.2em; color: #00356B;">Weiyan Shi</a></br>
              <p>Northeastern University</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <br>
    <br>


    <!-- Sponsors -->
    <section id="sponsors" class="section-with-bg">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Sponsors</h2>
        </div>
        <div class="row justify-content-center">
          <div class="col-md-4 col-sm-6 col-8">
            <div class="speaker" data-aos="fade-up" data-aos-delay="100" style="text-align: center;">
              <img src="assets/img/meta_logo.png" alt="Meta" class="img-fluid">
              <p style="font-size: 1.2em; font-weight: 500; margin-top: 10px;">Meta</p>
            </div>
          </div>
        </div>
        <div class="row justify-content-center">
          <div class="col-md-8 col-sm-10">
            <div class="speaker" data-aos="fade-up" data-aos-delay="100" style="text-align: center;">
              <div style="display: flex; justify-content: center; align-items: center; gap: 40px; flex-wrap: wrap;">
                <img src="assets/img/sponsors/uniphore_logo.jpg" alt="Uniphore" class="img-fluid" style="max-width: 200px;">
                <img src="assets/img/sponsors/orby_logo.jpg" alt="Orby AI" class="img-fluid" style="max-width: 200px;">
              </div>
              <p style="font-size: 1.2em; font-weight: 500; margin-top: 10px;">Uniphore / OrbyAI</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Partners -->
    <section id="partners" class="section-with-bg">
      <div class="container" data-aos="fade-up">
        <div class="section-header">
          <h2>Partners</h2>
        </div>
        <div class="row justify-content-center">
          <div class="col-md-4 col-sm-6 col-8">
            <div class="speaker" data-aos="fade-up" data-aos-delay="100" style="text-align: center;">
              <img src="assets/img/sponsors/prime.jpeg" alt="Prime Intellect" class="img-fluid">
              <p style="font-size: 1.2em; font-weight: 500; margin-top: 10px;">Prime Intellect</p>
            </div>
          </div>
        </div>
      </div>
    </section>
    
    <br>
    <br>




  </main><footer id="footer">
    <div class="container">
      <div class="copyright">
        </div>
      <div class="credits">
        Template adopted from <a href="https://set-llm.github.io/">SeT LLM @ ICLR 2024</a>
      </div>
    </div>
  </footer><a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <script src="assets/js/main.js"></script>


</body>

</html>